# CS-272 Semester Project - Assignment 1
## ICASSP 2026 Challenge: Cadenza CLIP1 - Lyric Intelligibility Prediction

### Project Overview
This project addresses the Cadenza Challenge for ICASSP 2026, focusing on predicting lyric intelligibility for listeners with hearing impairments. The goal is to analyze and model how well listeners can understand song lyrics when processed through different hearing aid configurations.

### Repository Structure
```
sem_3_ai_sem_proj/
├── report/              # LaTeX source and generated PDF
│   ├── report.tex       # Main LaTeX report document
│   ├── ieee_template.cls # IEEE template for formatting
│   └── report.pdf       # Generated final report (after compilation)
├── plots/               # All PDF figures generated by analysis
│   ├── figure_1_target_distribution.pdf
│   ├── figure_2_signal_comparison.pdf
│   ├── figure_3_word_length.pdf
│   ├── figure_4_word_frequency.pdf
│   ├── figure_5_spectral_centroid.pdf
│   ├── figure_6_edit_distance.pdf
│   └── figure_7_synthesis_interaction.pdf
├── code/                # Analysis code
│   └── eda.ipynb        # Jupyter Notebook for Exploratory Data Analysis
├── data/                # Dataset directory
│   └── cadenza_data/    # Cadenza CLIP1 dataset
│       ├── metadata/    # Training metadata (train_metadata.json)
│       ├── train/       # Audio files
│       │   ├── signals/      # Processed audio signals
│       │   └── unprocessed/  # Original unprocessed audio
│       └── manifest/    # Dataset manifest files
├── venv/                # Python virtual environment
├── requirements.txt     # Python package dependencies
└── README.md           # This file
```

### Dataset
The project uses the **Cadenza CLIP1 dataset** for ICASSP 2026, which includes:
- **Training metadata**: JSON file with listener responses, prompts, correctness scores, and hearing loss categories
- **Audio signals**: Both processed (hearing aid simulated) and unprocessed versions
- **Target variable**: `correctness` - a continuous score (0-1) representing lyric intelligibility

### Analyses Performed

#### 1. **Foundational Analysis**
   - **Figure 1**: Distribution of intelligibility scores (reveals bimodal pattern)
   - **Figure 2**: Waveform and spectrogram comparison (processed vs. unprocessed signals)

#### 2. **Lyrical Content Analysis**
   - **Figure 3**: Word length vs. correctness (linguistic complexity)
   - **Figure 4**: Word frequency vs. correctness (lexical familiarity)

#### 3. **Acoustic & Perceptual Analysis**
   - **Figure 5**: Spectral centroid vs. correctness (acoustic brightness)
   - **Figure 6**: Edit distance vs. correctness (listener error patterns)

#### 4. **Synthesis & Interaction**
   - **Figure 7**: Multi-faceted analysis across hearing loss categories

### How to Reproduce

#### Prerequisites
- Python 3.9 or higher
- LaTeX distribution (e.g., TeX Live, MiKTeX) for report compilation

#### Step-by-Step Instructions

1. **Clone the repository** (or ensure you're in the project directory)
   ```powershell
   cd "G:\My Drive\musab\BSCS 14B Musab\Musab BSCS 14B files\Semester 3\Artificial Intelligence\sem_3_ai_sem_proj"
   ```

2. **Activate the virtual environment**
   ```powershell
   .\venv\Scripts\Activate.ps1
   ```
   
   If you encounter execution policy issues on Windows:
   ```powershell
   Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
   ```

3. **Install required packages**
   ```powershell
   pip install -r requirements.txt
   ```

4. **Verify dataset location**
   - Ensure the Cadenza dataset is placed in `data/cadenza_data/`
   - Check that `train_metadata.json` exists in `data/cadenza_data/metadata/`
   - Verify audio files are in `data/cadenza_data/train/signals/` and `data/cadenza_data/train/unprocessed/`

5. **Run the analysis notebook**
   - Open `code/eda.ipynb` in Jupyter Notebook, JupyterLab, or VS Code
   - Run all cells sequentially to generate the 7 figures in `plots/`
   
   Alternatively, run from command line:
   ```powershell
   jupyter notebook code/eda.ipynb
   ```

6. **Compile the LaTeX report**
   ```powershell
   cd report
   pdflatex report.tex
   pdflatex report.tex  # Run twice for proper references
   ```

### Key Dependencies
- **pandas**: Data manipulation and analysis
- **numpy**: Numerical computations
- **matplotlib**: Plotting and visualization
- **seaborn**: Statistical visualizations
- **librosa**: Audio processing and feature extraction
- **wordfreq**: Word frequency analysis
- **python-Levenshtein**: String distance calculations

### Expected Outputs
After running the notebook, you should have:
- ✅ 7 PDF figures in the `plots/` directory
- ✅ Comprehensive data analysis with statistics printed in the notebook
- ✅ Full dataset analysis including all response types (including '#' responses representing zero intelligibility)

### Notes
- **Audio processing** is performed on a 5% stratified sample to balance computational efficiency with statistical validity
- **Metadata analysis** uses the full dataset for maximum statistical power
- The `'#'` symbol in responses represents cases where listeners could not identify any words (correctness = 0.0). These are valid data points representing the lowest intelligibility and are included in all analyses
- Edit distance calculations handle `'#'` responses by returning NaN for that specific metric, as Levenshtein distance is undefined for non-transcription symbols
- All figures are generated in PDF format suitable for publication

### Authors
- Musab (BSCS 14B)
- CS-272 Artificial Intelligence - Semester 3

### License
This project is part of academic coursework for the ICASSP 2026 Cadenza Challenge.

### Contact
For questions or issues, please contact the project maintainer or refer to the course instructor.

---

**Last Updated**: October 17, 2025
